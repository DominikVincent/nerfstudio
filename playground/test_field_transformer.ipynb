{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch_points3d/core/data_transform/../../../tinycudann/modules.py:52: UserWarning: tinycudann was built for lower compute capability (75) than the system's (86). Performance may be suboptimal.\n",
      "  warnings.warn(f\"tinycudann was built for lower compute capability ({cc}) than the system's ({system_compute_capability}). Performance may be suboptimal.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nerfstudio.model_components.nesf_components import FieldTransformerConfig, TranformerEncoderModelConfig\n",
    "import torch\n",
    "import lovely_tensors as lt\n",
    "import time\n",
    "from nerfstudio.utils.nesf_utils import visualize_point_batch\n",
    "lt.monkey_patch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count:  82147\n"
     ]
    }
   ],
   "source": [
    "FEATURE_DIM = 48\n",
    "DEVICE = \"cuda:0\"\n",
    "model_config = FieldTransformerConfig(\n",
    "    knn=128,\n",
    "    mode = \"transformer\",\n",
    "    transformer=TranformerEncoderModelConfig(\n",
    "        num_layers=2,\n",
    "        num_heads=2,\n",
    "    )\n",
    ")\n",
    "model = model_config.setup(input_size=FEATURE_DIM)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# parameter count\n",
    "print(\"Parameter count: \", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NP=49152\n",
    "NP=4915\n",
    "# QP=24576\n",
    "QP=2457\n",
    "CHUNK_SIZE=4096\n",
    "\n",
    "neural_points = torch.rand(NP, 3, device=DEVICE)\n",
    "neural_features = torch.rand(NP, FEATURE_DIM, device=DEVICE, requires_grad=True)\n",
    "query_points = torch.rand(QP, 3, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max cuda memory allocated:  1.3056640625 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max cuda memory allocated:  52.96435546875 MB\n",
      "Is identical:  tensor bool cuda:0 True\n",
      "Is identical:  True\n",
      "Max cuda memory allocated:  52.96435546875 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Max cuda memory allocated: \", torch.cuda.max_memory_allocated(DEVICE) / 1024 / 1024, \"MB\")\n",
    "k_idx1, k_dist = model.get_k_closest_points_deprecated(query_points, neural_points)\n",
    "print(\"Max cuda memory allocated: \", torch.cuda.max_memory_allocated(DEVICE) / 1024 / 1024, \"MB\")\n",
    "k_idx2, k_dist2 = model.get_k_closest_points(query_points, neural_points)\n",
    "\n",
    "print(\"Is identical: \", torch.all(k_idx1 == k_idx2))\n",
    "print(\"Is identical: \", torch.allclose(k_dist, k_dist2))\n",
    "print(\"Max cuda memory allocated: \", torch.cuda.max_memory_allocated(DEVICE) / 1024 / 1024, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([24576, 3]) torch.Size([49152, 48]) torch.Size([49152, 3])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Querying  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24576</span> points in neural field of  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">49152</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Querying  \u001b[1;36m24576\u001b[0m points in neural field of  \u001b[1;36m49152\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest_ind torch.Size([24576, 64])\n",
      "closest ind tensor[24576, 64] i64 \u001b[38;2;127;127;127mall_zeros\u001b[0m cuda:0\n",
      "rel_pos_feat torch.Size([24576, 65, 51])\n",
      "Max memory allocated:  26940.9140625 MB\n",
      "Time:  0.02077317237854004 s\n",
      "torch.Size([24576, 48])\n",
      "tensor[24576, 48] n=1179648 x∈[-2.136, 1.849] μ=-0.129 σ=0.633 grad AddmmBackward0 cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.config.knn = 64\n",
    "time1 = time.time()\n",
    "\n",
    "#process in chunks\n",
    "K=1\n",
    "# for i in range(0, QP, CHUNK_SIZE):\n",
    "#     K+=1\n",
    "#     qp = query_points[i:i+CHUNK_SIZE]\n",
    "outs = model(query_points, neural_features, neural_points)\n",
    "\n",
    "time2 = time.time()\n",
    "\n",
    "print(\"Max memory allocated: \", torch.cuda.max_memory_allocated() / 1024 / 1024, \"MB\")\n",
    "print(\"Time: \", (time2 - time1) / K, \"s\")\n",
    "print(outs.shape)\n",
    "print(outs)\n",
    "\n",
    "# reset torch stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor[1, 128, 3] \u001b[38;2;127;127;127mall_zeros\u001b[0m cuda:0\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio2/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "points = torch.arange(0, 1, 0.01, device=DEVICE)\n",
    "points = torch.stack(torch.meshgrid(points, points, points), dim=-1).reshape(-1, 3)\n",
    "\n",
    "ind = model.get_k_closest_points(torch.tensor([0.5, 0.5, 0.5], device=DEVICE).unsqueeze(0), points)\n",
    "\n",
    "\n",
    "closest_points = points[ind]\n",
    "print(closest_points)\n",
    "print(closest_points.p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
