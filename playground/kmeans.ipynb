{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def kmeans(points, x_prime):\n",
    "    n = points.size(0)\n",
    "    k = n // x_prime\n",
    "    \n",
    "    # Initialize centroids randomly\n",
    "    centroids = points[torch.randperm(n)[:k]]\n",
    "    \n",
    "    old_centroids = centroids.clone()  # Initialize old_centroids\n",
    "    \n",
    "    while True:\n",
    "        # Assign each point to the nearest centroid\n",
    "        distances = torch.cdist(points, centroids)\n",
    "        _, assignments = torch.min(distances, dim=1)\n",
    "        \n",
    "        # Check if any cluster is too large or too small\n",
    "        cluster_sizes = torch.bincount(assignments, minlength=k)\n",
    "        if (cluster_sizes != x_prime).any():\n",
    "            # Re-assign points to different clusters\n",
    "            for i in range(k):\n",
    "                while cluster_sizes[i] > x_prime:\n",
    "                    # Find the point farthest from the centroid and re-assign it\n",
    "                    farthest = torch.argmin(distances[:, i])\n",
    "                    assignments[farthest] = -1  # Mark point as unassigned\n",
    "                    cluster_sizes[i] -= 1\n",
    "                    \n",
    "                while cluster_sizes[i] < x_prime:\n",
    "                    # Find the point closest to the centroid and re-assign it\n",
    "                    closest = torch.argmin(distances[:, i])\n",
    "                    if assignments[closest] == -1:  # Skip points that are already unassigned\n",
    "                        continue\n",
    "                    assignments[closest] = i\n",
    "                    cluster_sizes[i] += 1\n",
    "        \n",
    "        # Calculate new centroids\n",
    "        centroids = torch.stack([points[assignments == i].mean(dim=0) for i in range(k)])\n",
    "        \n",
    "        # Check if the algorithm has converged\n",
    "        if (centroids == old_centroids).all():\n",
    "            break\n",
    "        \n",
    "        old_centroids = centroids\n",
    "    \n",
    "    # Return cluster assignments\n",
    "    return assignments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1536]) tensor([11,  2,  1,  ..., 11, 11, 11])\n"
     ]
    }
   ],
   "source": [
    "points = torch.randn((512*3, 3))\n",
    "\n",
    "x_prime = 128\n",
    "\n",
    "assignments = kmeans(points, x_prime)\n",
    "print(assignments.shape, assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1) tensor(5)\n",
      "tensor(0) tensor(140)\n",
      "tensor(1) tensor(131)\n",
      "tensor(2) tensor(137)\n",
      "tensor(3) tensor(121)\n",
      "tensor(4) tensor(96)\n",
      "tensor(5) tensor(122)\n",
      "tensor(6) tensor(102)\n",
      "tensor(7) tensor(122)\n",
      "tensor(8) tensor(100)\n",
      "tensor(9) tensor(135)\n",
      "tensor(10) tensor(109)\n",
      "tensor(11) tensor(216)\n"
     ]
    }
   ],
   "source": [
    "# count the number of occurance of each value in assignemnts\n",
    "for values in torch.unique(assignments):\n",
    "    print(values, (assignments == values).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "XA must be a 2-dimensional array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m group_points \u001b[39m=\u001b[39m points[labels \u001b[39m==\u001b[39m i]\n\u001b[1;32m     32\u001b[0m centroid \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mcluster_centers_[i]\n\u001b[0;32m---> 33\u001b[0m distances \u001b[39m=\u001b[39m cdist(group_points, centroid\u001b[39m.\u001b[39;49mreshape(\u001b[39m1\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m     34\u001b[0m farthest_point_idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(torch\u001b[39m.\u001b[39mtensor(distances))\n\u001b[1;32m     35\u001b[0m farthest_point \u001b[39m=\u001b[39m group_points[farthest_point_idx]\n",
      "File \u001b[0;32m/data/vision/polina/projects/wmh/dhollidt/conda/envs/nerfstudio3/lib/python3.8/site-packages/scipy/spatial/distance.py:2924\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   2921\u001b[0m sB \u001b[39m=\u001b[39m XB\u001b[39m.\u001b[39mshape\n\u001b[1;32m   2923\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(s) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 2924\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mXA must be a 2-dimensional array.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2925\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sB) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   2926\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mXB must be a 2-dimensional array.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: XA must be a 2-dimensional array."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# generate N 3D points\n",
    "N = 100\n",
    "points = torch.randn(N, 3)\n",
    "\n",
    "# set the number of clusters\n",
    "k = 5\n",
    "\n",
    "# initialize k-means algorithm\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "\n",
    "# fit the algorithm to the data\n",
    "kmeans.fit(points)\n",
    "\n",
    "# get the cluster labels for each point\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# calculate the number of points in each group\n",
    "counts = torch.tensor([torch.sum(torch.tensor(labels) == i) for i in range(k)])\n",
    "\n",
    "# adjust the cluster assignments\n",
    "while not torch.all(counts == N//k):\n",
    "    # find the groups with more than N/k points\n",
    "    overfull_groups = torch.where(counts > N//k)[0]\n",
    "    if overfull_groups.nelement() > 0:\n",
    "        # iterate over each overfull group\n",
    "        for i in overfull_groups:\n",
    "            group_points = points[labels == i]\n",
    "            centroid = kmeans.cluster_centers_[i]\n",
    "            distances = cdist(group_points, centroid.reshape(1,-1))\n",
    "            farthest_point_idx = torch.argmax(torch.tensor(distances))\n",
    "            farthest_point = group_points[farthest_point_idx]\n",
    "            # find the closest underfull group\n",
    "            underfull_groups = torch.where(counts < N//k)[0]\n",
    "            distances = cdist(kmeans.cluster_centers_[underfull_groups], farthest_point.reshape(1,-1))\n",
    "            closest_group_idx = torch.argmin(torch.tensor(distances))\n",
    "            closest_group = underfull_groups[closest_group_idx]\n",
    "            # reassign the farthest point to the closest underfull group\n",
    "            labels[torch.where(labels == i)[0][farthest_point_idx]] = closest_group\n",
    "            counts[i] -= 1\n",
    "            counts[closest_group] += 1\n",
    "\n",
    "    # find the groups with fewer than N/k points\n",
    "    underfull_groups = torch.where(counts < N//k)[0]\n",
    "    if underfull_groups.nelement() > 0:\n",
    "        # iterate over each underfull group\n",
    "        for i in underfull_groups:\n",
    "            group_points = points[labels == i]\n",
    "            centroid = kmeans.cluster_centers_[i]\n",
    "            # find the closest unassigned point\n",
    "            distances = cdist(points, centroid.reshape(1,-1))\n",
    "            unassigned_points = torch.where(labels == -1)[0]\n",
    "            unassigned_distances = distances[unassigned_points, i]\n",
    "            closest_point_idx = torch.argmin(unassigned_distances)\n",
    "            closest_point = points[unassigned_points[closest_point_idx]]\n",
    "            # assign the closest un\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2455,  1.5602, -0.3678],\n",
      "        [-0.2455,  1.5602, -0.3678],\n",
      "        [-0.2455,  1.5602, -0.3678],\n",
      "        [-0.2455,  1.5602, -0.3678],\n",
      "        [-0.2455,  1.5602, -0.3678],\n",
      "        [-0.2455,  1.5602, -0.3678],\n",
      "        [-0.2455,  1.5602, -0.3678],\n",
      "        [-0.2455,  1.5602, -0.3678],\n",
      "        [-0.2455,  1.5602, -0.3678],\n",
      "        [-0.2455,  1.5602, -0.3678],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [ 0.7741, -0.7501,  0.8914],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-1.4721,  0.4531, -0.3946],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.7109, -0.3768, -0.2436],\n",
      "        [-0.1310,  0.7726, -0.5012],\n",
      "        [-0.1310,  0.7726, -0.5012],\n",
      "        [-0.1310,  0.7726, -0.5012],\n",
      "        [-0.1310,  0.7726, -0.5012],\n",
      "        [-0.1310,  0.7726, -0.5012],\n",
      "        [-0.1310,  0.7726, -0.5012],\n",
      "        [-0.1310,  0.7726, -0.5012],\n",
      "        [-0.1310,  0.7726, -0.5012],\n",
      "        [-0.1310,  0.7726, -0.5012],\n",
      "        [-0.1310,  0.7726, -0.5012]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "k = 5\n",
    "matrix = torch.randn(k, 3)\n",
    "\n",
    "# Reshape the matrix to [k, 1, 3]\n",
    "reshaped_matrix = matrix.view(k, 1, 3)\n",
    "\n",
    "# Repeat each row along dimension 1, each row is repeated 10 times\n",
    "inflated_matrix = reshaped_matrix.repeat(1, 10, 1)\n",
    "\n",
    "# Reshape the inflated matrix back to [10*k, 3]\n",
    "inflated_matrix = inflated_matrix.view(10*k, 3)\n",
    "\n",
    "print(inflated_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "points = torch.empty((0,3))\n",
    "points2 = torch.randn((10,3))\n",
    "\n",
    "points_all = torch.cat([points, points2], dim=0)\n",
    "print(points_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
